[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrixDisplay",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "RocCurveDisplay",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "RocCurveDisplay",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "LabelEncoder",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "label_binarize",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "label_binarize",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "SimpleImputer",
        "importPath": "sklearn.impute",
        "description": "sklearn.impute",
        "isExtraImport": true,
        "detail": "sklearn.impute",
        "documentation": {}
    },
    {
        "label": "NeuralNet",
        "kind": 6,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "class NeuralNet(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(NeuralNet, self).__init__()\n        self.fc1 = nn.Linear(input_dim, 256)\n        self.fc2 = nn.Linear(256, output_dim)\n        self.relu = nn.ReLU()\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "squash",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def squash(value):\n    value = np.clip(value, -500, 500)  # Clip extreme values\n    return 1.0 / (1.0 + np.exp(-value))\n# Normalizes a dataset using the squash function\ndef normalize_dataset(dataset):\n    return squash(dataset)\n# Load MNIST dataset\ndef load_mnist():\n    print(\"Loading MNIST dataset...\")\n    transform = transforms.Compose([",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "normalize_dataset",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def normalize_dataset(dataset):\n    return squash(dataset)\n# Load MNIST dataset\ndef load_mnist():\n    print(\"Loading MNIST dataset...\")\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "load_mnist",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def load_mnist():\n    print(\"Loading MNIST dataset...\")\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n    test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n    x_train = train_dataset.data.numpy() / 255.0\n    y_train = train_dataset.targets.numpy()",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "load_fashion_mnist",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def load_fashion_mnist():\n    print(\"Loading Fashion MNIST dataset...\")\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    train_dataset = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n    test_dataset = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n    x_train = train_dataset.data.numpy() / 255.0\n    y_train = train_dataset.targets.numpy()",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "load_cifar10",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def load_cifar10():\n    print(\"Loading CIFAR-10 dataset...\")\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,), (0.5,))\n    ])\n    train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n    x_train = train_dataset.data / 255.0\n    y_train = np.array(train_dataset.targets)",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "load_data",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def load_data(train_file_path, test_file_path, task_type='classification'):\n    \"\"\"\n    Load and preprocess data from CSV files.\n    Args:\n        train_file_path (str): Path to the training dataset CSV.\n        test_file_path (str): Path to the testing dataset CSV.\n        task_type (str): Either 'classification' or 'regression'.\n    Returns:\n        x_train, y_train, x_test, y_test: Preprocessed datasets.\n    \"\"\"",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def plot_metrics(losses, accuracies):\n    plt.figure(figsize=(10, 6))\n    epochs = range(1, len(losses) + 1)\n    plt.plot(epochs, losses, label=\"Loss\", color=\"red\")\n    plt.plot(epochs, accuracies, label=\"Accuracy\", color=\"blue\")\n    plt.title(\"Training Loss and Accuracy\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Value\")\n    plt.legend()\n    plt.savefig(\"training_metrics.png\")",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "evaluate_model",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def evaluate_model(model, x_test, y_test, device, task_type='classification'):\n    model.eval()\n    with torch.no_grad():\n        test_outputs = model(x_test)\n        if task_type in ['regression', 'r']:\n            test_outputs = test_outputs.squeeze()\n            y_true = y_test.cpu().numpy()\n            y_pred = test_outputs.cpu().numpy()\n            mse = mean_squared_error(y_true, y_pred)\n            mae = mean_absolute_error(y_true, y_pred)",
        "detail": "python_version.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "python_version.main",
        "description": "python_version.main",
        "peekOfCode": "def main():\n    dataset_choice = int(input(\n        \"Choose the dataset to use (1 for MNIST, 2 for Fashion MNIST, 3 for CIFAR-10, 4 for Custom CSV Data): \").strip())\n    epochs = int(input(\"Enter the number of training epochs: \").strip())\n    # Load dataset\n    if dataset_choice == 1:\n        x_train, y_train, x_test, y_test = load_mnist()\n       #print(\"X_train shape:\", x_train.shape)\n        #print(\"y_train shape:\", y_train.shape)\n        #print(\"X_test shape:\", x_test.shape)",
        "detail": "python_version.main",
        "documentation": {}
    }
]